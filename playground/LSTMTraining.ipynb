{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-08T22:33:56.130471Z",
     "iopub.status.busy": "2024-12-08T22:33:56.130192Z",
     "iopub.status.idle": "2024-12-08T22:34:00.435583Z",
     "shell.execute_reply": "2024-12-08T22:34:00.434747Z",
     "shell.execute_reply.started": "2024-12-08T22:33:56.130444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import word_tokenize, WhitespaceTokenizer\n",
    "from contractions import fix\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:34:00.437176Z",
     "iopub.status.busy": "2024-12-08T22:34:00.436638Z",
     "iopub.status.idle": "2024-12-08T22:34:00.445919Z",
     "shell.execute_reply": "2024-12-08T22:34:00.444917Z",
     "shell.execute_reply.started": "2024-12-08T22:34:00.437131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, comments, labels, glove_vocab, max_length):\n",
    "        self.texts = comments.tolist()\n",
    "        self.labels = labels.tolist()\n",
    "        self.glove_vocab = glove_vocab\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = WhitespaceTokenizer()\n",
    "        self.processed_texts = [self._preprocess(text) for text in self.texts]\n",
    "\n",
    "    def _preprocess(self, text):\n",
    "        # Expand contractions\n",
    "        text = fix(text)\n",
    "        # Convert to lower case\n",
    "        text = text.lower()\n",
    "        # Replace underscores with spaces\n",
    "        text = re.sub(r'[_]', ' ', text)\n",
    "        # Removing characters that usually don't add meaning to a sentence\n",
    "        text = re.sub(r\"[^?$.-:()%@!&=+/><,a-zA-Z\\s0-9\\w]\", '', text)\n",
    "        # Changes multiple occurrences of these special characters to only one occurrence. For example '???' to '?'\n",
    "        text = re.sub(r'([?.!#$%&()*+,-/:;_<=>@[^`|])\\1+', r'\\1', text)\n",
    "        # Inserts a space before and after special characters so embeddings can catch them\n",
    "        text = re.sub(r'([?.!#$%&()*+,-/:;_<=>@[^`|])', r' \\1 ', text)\n",
    "        # Removes extra spaces that may have come in from the previous operation\n",
    "        text = re.sub(r'([\\s])\\1+', r'\\1', text)\n",
    "        # Tokenize\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        # Filter tokens not in GloVe vocab\n",
    "        tokens = [token if token in self.glove_vocab else '<unk>' for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: Update this function based on the format required for the model\n",
    "        tokens = self.processed_texts[idx]\n",
    "        # Pad or truncate to max_length\n",
    "        if len(tokens) < self.max_length:\n",
    "            tokens += ['<pad>'] * (self.max_length - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:self.max_length]\n",
    "        # Convert tokens to indices\n",
    "        indices = [self.glove_vocab[token] for token in tokens]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return torch.tensor(indices, dtype=torch.long), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:34:00.448583Z",
     "iopub.status.busy": "2024-12-08T22:34:00.448219Z",
     "iopub.status.idle": "2024-12-08T22:34:00.461322Z",
     "shell.execute_reply": "2024-12-08T22:34:00.460652Z",
     "shell.execute_reply.started": "2024-12-08T22:34:00.448545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_glove_vocab(filepath='../data/glove.6B/glove.6B.50d.txt'):\n",
    "    glove_vocab = {}\n",
    "    embeddings = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = [float(x) for x in values[1:]]\n",
    "            glove_vocab[word] = idx\n",
    "            embeddings.append(vector)\n",
    "    glove_vocab['<pad>'] = len(embeddings)\n",
    "    embeddings.append([0.0] * len(vector))\n",
    "    glove_vocab['<unk>'] = len(embeddings)\n",
    "    embeddings.append([1.0] * len(vector))\n",
    "    return glove_vocab, torch.tensor(embeddings, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:34:00.462489Z",
     "iopub.status.busy": "2024-12-08T22:34:00.462237Z",
     "iopub.status.idle": "2024-12-08T22:34:15.642446Z",
     "shell.execute_reply": "2024-12-08T22:34:15.641656Z",
     "shell.execute_reply.started": "2024-12-08T22:34:00.462465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "glove_vocab, glove_embeddings = load_glove_vocab('/kaggle/input/gloveembed/glove.6B.100d.txt') #TODO: Tune for optimal distance (50, 100, 200, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:34:15.643877Z",
     "iopub.status.busy": "2024-12-08T22:34:15.643548Z",
     "iopub.status.idle": "2024-12-08T22:34:37.022320Z",
     "shell.execute_reply": "2024-12-08T22:34:37.021660Z",
     "shell.execute_reply.started": "2024-12-08T22:34:15.643842Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
    "df = df.dropna(subset=['comment_text'])\n",
    "df['target'] = df['target'].round(0).astype(int)\n",
    "# df = df[:int(0.5*len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:34:37.023748Z",
     "iopub.status.busy": "2024-12-08T22:34:37.023411Z",
     "iopub.status.idle": "2024-12-08T22:34:37.471113Z",
     "shell.execute_reply": "2024-12-08T22:34:37.470382Z",
     "shell.execute_reply.started": "2024-12-08T22:34:37.023706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['comment_text'], df['target'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:34:37.472578Z",
     "iopub.status.busy": "2024-12-08T22:34:37.472209Z",
     "iopub.status.idle": "2024-12-08T22:37:11.109412Z",
     "shell.execute_reply": "2024-12-08T22:37:11.108663Z",
     "shell.execute_reply.started": "2024-12-08T22:34:37.472540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = JigsawDataset(X_train, y_train, glove_vocab, max_length=220)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:37:11.110620Z",
     "iopub.status.busy": "2024-12-08T22:37:11.110300Z",
     "iopub.status.idle": "2024-12-08T22:37:27.258214Z",
     "shell.execute_reply": "2024-12-08T22:37:27.257518Z",
     "shell.execute_reply.started": "2024-12-08T22:37:11.110593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = JigsawDataset(X_test, y_test, glove_vocab, max_length=220)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:37:27.261682Z",
     "iopub.status.busy": "2024-12-08T22:37:27.261300Z",
     "iopub.status.idle": "2024-12-08T22:37:27.359194Z",
     "shell.execute_reply": "2024-12-08T22:37:27.358365Z",
     "shell.execute_reply.started": "2024-12-08T22:37:27.261651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: tensor([[  3124,      1,   6380,  ..., 400000, 400000, 400000],\n",
      "        [  2747,      2,     41,  ..., 400000, 400000, 400000],\n",
      "        [  2970,     25,      0,  ..., 400000, 400000, 400000],\n",
      "        ...,\n",
      "        [  8198,    285,    188,  ..., 400000, 400000, 400000],\n",
      "        [  4832,  16201,    188,  ..., 400000, 400000, 400000],\n",
      "        [ 13408, 139150,     14,  ..., 400000, 400000, 400000]])\n",
      "Label shape: tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    inputs, labels = batch\n",
    "    print(\"Input shape:\", inputs)\n",
    "    print(\"Label shape:\", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:37:27.360603Z",
     "iopub.status.busy": "2024-12-08T22:37:27.360281Z",
     "iopub.status.idle": "2024-12-08T22:37:27.368473Z",
     "shell.execute_reply": "2024-12-08T22:37:27.367574Z",
     "shell.execute_reply.started": "2024-12-08T22:37:27.360576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ToxicityClassifierLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim, output_dim, num_layers, dropout=None):\n",
    "        super(ToxicityClassifierLSTM, self).__init__()\n",
    "        vocab_size, embedding_dim = embedding_matrix.shape\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if dropout is not None else 0)\n",
    "        self.lstm_layer_1 = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.lstm_layer_2 = nn.LSTM(hidden_dim * 2, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.linear1 = nn.Linear(4 * hidden_dim, 4 * hidden_dim)\n",
    "        self.linear2 = nn.Linear(4 * hidden_dim, 4 * hidden_dim)\n",
    "        self.fc = nn.Linear(4 * hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        lstm_out, _ = self.lstm_layer_1(embedded)\n",
    "        lstm_out, _ = self.lstm_layer_2(lstm_out)\n",
    "        \n",
    "        # Global average pooling\n",
    "        avg_pool = torch.mean(lstm_out, 1)\n",
    "        # Global max pooling\n",
    "        max_pool, _ = torch.max(lstm_out, 1)\n",
    "        \n",
    "        pool_out = torch.cat((max_pool, avg_pool), 1)\n",
    "        linear1_out  = F.relu(self.linear1(pool_out))\n",
    "        linear2_out  = F.relu(self.linear2(pool_out))\n",
    "        \n",
    "        final_hidden_state = pool_out + linear1_out + linear2_out\n",
    "        \n",
    "        return self.fc(final_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:37:27.370155Z",
     "iopub.status.busy": "2024-12-08T22:37:27.369839Z",
     "iopub.status.idle": "2024-12-08T22:37:27.380342Z",
     "shell.execute_reply": "2024-12-08T22:37:27.379600Z",
     "shell.execute_reply.started": "2024-12-08T22:37:27.370115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_step(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(inputs).squeeze(1)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        all_preds.extend((predictions > 0.5).int().cpu().numpy())\n",
    "        all_labels.extend(labels.int().cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss / len(train_loader), accuracy\n",
    "\n",
    "\n",
    "def evaluate_step(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            predictions = model(inputs).squeeze(1)\n",
    "            loss = criterion(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            all_preds.extend((predictions > 0.5).int().cpu().numpy())\n",
    "            all_labels.extend(labels.int().cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss / len(test_loader), accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:37:27.381699Z",
     "iopub.status.busy": "2024-12-08T22:37:27.381383Z",
     "iopub.status.idle": "2024-12-08T22:37:27.394088Z",
     "shell.execute_reply": "2024-12-08T22:37:27.393291Z",
     "shell.execute_reply.started": "2024-12-08T22:37:27.381664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(train_loader, test_loader, glove_vocab, glove_embeddings):\n",
    "    # Hyperparameters\n",
    "    HIDDEN_DIM = 128\n",
    "    OUTPUT_DIM = 1\n",
    "    NUM_LAYERS = 2\n",
    "    PAD_IDX = glove_vocab['<pad>']\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Initialize model\n",
    "    model = ToxicityClassifierLSTM(\n",
    "        embedding_matrix=glove_embeddings,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        num_layers=NUM_LAYERS,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Optimizer and Loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss(reduction='mean') #nn.BCELoss()\n",
    "\n",
    "    # Train and evaluate\n",
    "    EPOCHS = 3\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        train_loss, train_acc = train_step(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "        test_loss, test_acc = evaluate_step(model, test_loader, criterion, DEVICE)\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-08T22:37:27.395359Z",
     "iopub.status.busy": "2024-12-08T22:37:27.395021Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25530/50762 [07:45<07:37, 55.12it/s]"
     ]
    }
   ],
   "source": [
    "model = train(train_loader, test_loader, glove_vocab, glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(model, sentence, max_length=220):\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    tokens = test_dataset._preprocess(text=sentence)\n",
    "    if len(tokens) < max_length:\n",
    "        tokens += ['<pad>'] * (max_length - len(tokens))\n",
    "    else:\n",
    "        tokens = tokens[:max_length]\n",
    "    indices = torch.tensor([glove_vocab[token] for token in tokens], dtype=torch.long)\n",
    "    inputs = indices.to(DEVICE)\n",
    "    predictions = model(inputs.unsqueenze(0)).squeeze(1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1375107,
     "sourceId": 12500,
     "sourceType": "competition"
    },
    {
     "datasetId": 6047831,
     "sourceId": 9855271,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
