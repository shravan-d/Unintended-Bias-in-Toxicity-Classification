{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary files: all_data.csv, dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:42:25.485243Z",
     "iopub.status.busy": "2024-12-10T00:42:25.484347Z",
     "iopub.status.idle": "2024-12-10T00:42:38.774145Z",
     "shell.execute_reply": "2024-12-10T00:42:38.773130Z",
     "shell.execute_reply.started": "2024-12-10T00:42:25.485210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:42:38.776474Z",
     "iopub.status.busy": "2024-12-10T00:42:38.775914Z",
     "iopub.status.idle": "2024-12-10T00:43:02.454983Z",
     "shell.execute_reply": "2024-12-10T00:43:02.454111Z",
     "shell.execute_reply.started": "2024-12-10T00:42:38.776443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import full dataset\n",
    "df = pd.read_csv('all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:27:06.816600Z",
     "iopub.status.busy": "2024-12-10T00:27:06.815803Z",
     "iopub.status.idle": "2024-12-10T00:27:06.821406Z",
     "shell.execute_reply": "2024-12-10T00:27:06.820394Z",
     "shell.execute_reply.started": "2024-12-10T00:27:06.816555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing the text \n",
    "def clean_text(text):\n",
    "    ''' Removes punctuation and special characters, lowercases text'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Do not remove stop words to leave more context for Roberta\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:27:08.297573Z",
     "iopub.status.busy": "2024-12-10T00:27:08.297199Z",
     "iopub.status.idle": "2024-12-10T00:27:23.917171Z",
     "shell.execute_reply": "2024-12-10T00:27:23.916452Z",
     "shell.execute_reply.started": "2024-12-10T00:27:08.297542Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29992 159782\n"
     ]
    }
   ],
   "source": [
    "df['comment_text'] = df['comment_text'].fillna('') # Remove NaN values\n",
    "df['cleaned_comment'] = df['comment_text'].apply(clean_text) \n",
    "\n",
    "df['target'] = df['toxicity'] # Mark target col\n",
    "data = dataset.split_dataframe(df) # Apply common split \n",
    "\n",
    "# Assign dfs\n",
    "traindf = data[0]\n",
    "testdf = data[1]\n",
    "\n",
    "# Downsizing dataset for reasonable runtimes with our resources \n",
    "trainsubset = traindf[:25000]\n",
    "testsubset = testdf[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsubset.to_csv('trainsubset.csv')\n",
    "testsubset.to_csv('testsubset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:22:25.048778Z",
     "iopub.status.busy": "2024-12-10T00:22:25.048055Z",
     "iopub.status.idle": "2024-12-10T00:22:25.972780Z",
     "shell.execute_reply": "2024-12-10T00:22:25.972083Z",
     "shell.execute_reply.started": "2024-12-10T00:22:25.048734Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Intialize roberta\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=1)  # labels=1 for regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:27:27.807187Z",
     "iopub.status.busy": "2024-12-10T00:27:27.806889Z",
     "iopub.status.idle": "2024-12-10T00:27:33.150794Z",
     "shell.execute_reply": "2024-12-10T00:27:33.150050Z",
     "shell.execute_reply.started": "2024-12-10T00:27:27.807159Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize with Roberta\n",
    "\n",
    "Xtrain = list(trainsubset['cleaned_comment'])\n",
    "ytrain = list(trainsubset['toxicity'])\n",
    "Xtest = list(testsubset['cleaned_comment'])\n",
    "ytest = list(testsubset['toxicity'])\n",
    "\n",
    "# Tokenize data, add padding and truncation to match sizing, set maximum length of tokens per comment\n",
    "Xtrain_encodings = tokenizer(Xtrain, truncation=True, padding=True, max_length=200, return_tensors='pt') \n",
    "Xtest_encodings = tokenizer(Xtest, truncation=True, padding=True, max_length=200, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:29:51.550022Z",
     "iopub.status.busy": "2024-12-10T00:29:51.549177Z",
     "iopub.status.idle": "2024-12-10T00:29:51.555359Z",
     "shell.execute_reply": "2024-12-10T00:29:51.554483Z",
     "shell.execute_reply.started": "2024-12-10T00:29:51.549988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to tensors to prepare for dataloader \n",
    "ytrain_tensor = torch.tensor(ytrain, dtype=torch.float)\n",
    "ytest_tensor = torch.tensor(ytest, dtype=torch.float)\n",
    "\n",
    "Xtraintorch = torch.utils.data.TensorDataset(Xtrain_encodings['input_ids'], Xtrain_encodings['attention_mask'], ytrain_tensor)\n",
    "Xtesttorch = torch.utils.data.TensorDataset(Xtest_encodings['input_ids'], Xtest_encodings['attention_mask'], ytest_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:29:52.075389Z",
     "iopub.status.busy": "2024-12-10T00:29:52.074669Z",
     "iopub.status.idle": "2024-12-10T00:29:52.080910Z",
     "shell.execute_reply": "2024-12-10T00:29:52.079794Z",
     "shell.execute_reply.started": "2024-12-10T00:29:52.075355Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_dataloader = DataLoader(Xtraintorch, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(Xtesttorch, batch_size=128, shuffle=True)\n",
    "# test different batch sizes to reduce running time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: tried with batch size 8, 1000 rows of training data, 1 epoch: 10 min running time to train w Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:18:56.316395Z",
     "iopub.status.busy": "2024-12-10T00:18:56.315486Z",
     "iopub.status.idle": "2024-12-10T00:18:56.320410Z",
     "shell.execute_reply": "2024-12-10T00:18:56.319494Z",
     "shell.execute_reply.started": "2024-12-10T00:18:56.316349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Move to GPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "roberta = roberta.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:29:56.717683Z",
     "iopub.status.busy": "2024-12-10T00:29:56.716949Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:43<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 0.13646246492862701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:45<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss 0.11496267467737198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:45<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss 0.10320953279733658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:45<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss 0.09113254398107529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [02:45<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss 0.10897951573133469\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(roberta.parameters(), lr=0.001) \n",
    "roberta.train()\n",
    "\n",
    "for epoch in range(5):  \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        \n",
    "        # Assign input data and labels from batch\n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "        # Forward pass: Compute predictions and loss\n",
    "        outputs = roberta(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()  # backpropagate loss\n",
    "        optimizer.step() \n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}: Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T00:19:30.944075Z",
     "iopub.status.busy": "2024-12-10T00:19:30.943734Z",
     "iopub.status.idle": "2024-12-10T00:19:30.950184Z",
     "shell.execute_reply": "2024-12-10T00:19:30.949230Z",
     "shell.execute_reply.started": "2024-12-10T00:19:30.944045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader):\n",
    "    ''' Evaluate model on test data using same framework as the training loop\n",
    "    Params: model: torch.nn.Module, test_dataloader: torch.dataloader \n",
    "    Output: tuple: pred (list) of predicted toxicity scores for the test data, actual (list) of true scores\n",
    "    '''\n",
    "    model.eval()\n",
    "    pred = []\n",
    "    actual = []\n",
    "    \n",
    "    with torch.no_grad(): # for faster running \n",
    "        for batch in tqdm(test_dataloader):\n",
    "            # Get the input data and labels from the batch\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            \n",
    "            # Forward pass: Compute predictions\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            pred.extend(logits.cpu().numpy())\n",
    "            actual.extend(labels.cpu().numpy()) \n",
    "\n",
    "    return pred, actual\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:05<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "pred1, actual1 = evaluate_model(roberta, test_dataloader)\n",
    "\n",
    "# Calculate MSE of roberta model, trained with batch size 128, 2500 rows of test data, 1 epoch\n",
    "mse1 = mean_squared_error(actual1, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Roberta model using 25000/2500 data split: 0.20515302072255853\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean Squared Error for Roberta model using 25000/2500 data split: {mse1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Low MSE and Loss on Roberta toxicity predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating disparate bias for comments that include identities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3103681/2622073997.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainsubset[identities] = trainsubset[identities].fillna(0.0)\n",
      "/tmp/ipykernel_3103681/2622073997.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  testsubset[identities] = testsubset[identities].fillna(0.0)\n"
     ]
    }
   ],
   "source": [
    "# Add identity markers to df\n",
    "identities = ['male', 'female', 'transgender',\n",
    "       'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
    "       'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
    "       'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
    "       'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
    "       'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
    "       'other_disability']\n",
    "\n",
    "# Treat NaN values in identity cols\n",
    "\n",
    "trainsubset[identities] = trainsubset[identities].fillna(0.0)\n",
    "testsubset[identities] = testsubset[identities].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save previous Roberta predictions to test for bias\n",
    "pred_bias = testsubset.copy()\n",
    "pred_bias['predicted_toxicity'] = pred1 # append roberta's predictions to df \n",
    "\n",
    "pred_bias.to_csv('RoBERTa_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bias(df, identities):\n",
    "    '''Find disparate bias/difference between the avg toxicity scores between comments containing \n",
    "    identities and comments not containing identities.  '''\n",
    "    scores = {}\n",
    "    for id in identities:\n",
    "        identities_and_toxicity = df[df[id] == 1]['predicted_toxicity']\n",
    "        no_identities_and_toxicity = df[df[id] == 0]['predicted_toxicity']\n",
    "\n",
    "        avg_with_id = identities_and_toxicity.mean()\n",
    "        avg_no_id = no_identities_and_toxicity.mean()\n",
    "        \n",
    "        disparity = avg_with_id - avg_no_id \n",
    "        \n",
    "        scores[id] = disparity\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Scores (Disparate Impact) per Identity:\n",
      "male: [0.02802683]\n",
      "female: [-0.01844062]\n",
      "transgender: [-0.60224073]\n",
      "other_gender: [nan]\n",
      "heterosexual: [0.04344688]\n",
      "homosexual_gay_or_lesbian: [0.01882699]\n",
      "bisexual: [nan]\n",
      "other_sexual_orientation: [nan]\n",
      "christian: [-0.09505423]\n",
      "jewish: [-0.09174468]\n",
      "muslim: [0.08145554]\n",
      "hindu: [nan]\n",
      "buddhist: [nan]\n",
      "atheist: [-0.32830092]\n",
      "other_religion: [nan]\n",
      "black: [0.03684885]\n",
      "white: [-0.01509563]\n",
      "asian: [-0.01846347]\n",
      "latino: [0.14318106]\n",
      "other_race_or_ethnicity: [nan]\n",
      "physical_disability: [nan]\n",
      "intellectual_or_learning_disability: [nan]\n",
      "psychiatric_or_mental_illness: [0.08566711]\n",
      "other_disability: [nan]\n"
     ]
    }
   ],
   "source": [
    "detected_bias = count_bias(pred_bias, identities)\n",
    "print(\"Bias Scores (Disparate Impact) per Identity:\")\n",
    "for identity, score in detected_bias.items():\n",
    "    print(f\"{identity}: {score}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot disparate bias found with Roberta model predictions \n",
    "\n",
    "biasdf = pd.DataFrame.from_dict(detected_bias, orient='index', columns=['bias'])\n",
    "biasdf = biasdf.dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "biasdf.sort_values('bias', ascending=False).plot(kind='bar', legend=False, color='c')\n",
    "plt.title(\"RoBERTa's Disparate Impact per Identity Group\", fontsize=12)\n",
    "plt.ylabel('Bias Score', fontsize=12)\n",
    "plt.xticks(rotation=60, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting model to address bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an adversarial loss function and calculating correlation both were unsucessful in avoiding the OutofMemory issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def biasloss(predictions, labels, identities, bias_penalty_factor=0.5):\n",
    "    '''Calculates loss based on model's toxicity prediction with the bias penalty, found with mean\n",
    "    absolute difference between predictions and  \n",
    "     bias_penalty_factor: factor for how much to penalize bias'''\n",
    "    \n",
    "    loss = f.mse_loss(predictions.flatten(), labels)\n",
    "    mad = torch.mean(torch.abs(predictions.flatten() - identities.flatten()))\n",
    "\n",
    "    # Calculate with  penalty\n",
    "    total_loss = loss + mad\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Roberta with bias penalty\n",
    "\n",
    "def train_with_penalty(model, train_dataloader, optimizer, device, bias_penalty_factor=0.5):\n",
    "    ''' Training roberta model with bias penalty'''\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()  # Clear gradients\n",
    "\n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels = batch[2].to(device)\n",
    "            identities_col = batch[3].to(device) \n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            pred = outputs.logits\n",
    "            # Compute the loss with bias regularization\n",
    "            loss = biasloss(pred, labels, identities_col, bias_penalty_factor)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply bias mitigation to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "Xtrainb = list(trainsubset['cleaned_comment'])\n",
    "ytrainb = list(trainsubset['toxicity'])\n",
    "Xtestb = list(testsubset['cleaned_comment'])\n",
    "ytestb = list(testsubset['toxicity'])\n",
    "\n",
    "# Reinitialize tokenizer and roberta model\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta2 = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=1)  \n",
    "\n",
    "Xtrain_encodings = tokenizer(Xtrainb, truncation=True, padding=True, max_length=200, return_tensors='pt') # choosing max length of comment\n",
    "Xtest_encodings = tokenizer(Xtestb, truncation=True, padding=True, max_length=200, return_tensors='pt')\n",
    "\n",
    "# Convert to tensors to prepare for dataloader \n",
    "ytrain_tensor = torch.tensor(ytrainb, dtype=torch.float)\n",
    "ytest_tensor = torch.tensor(ytestb, dtype=torch.float)\n",
    "\n",
    "# Including identities to calculate bias \n",
    "identities_col_train = torch.tensor(trainsubset[identities].values, dtype=torch.float)\n",
    "identities_col_test = torch.tensor(testsubset[identities].values, dtype=torch.float)\n",
    "Xtraintorch = TensorDataset(Xtrain_encodings['input_ids'], Xtrain_encodings['attention_mask'], ytrain_tensor, identities_col_train)\n",
    "Xtesttorch = TensorDataset(Xtest_encodings['input_ids'], Xtest_encodings['attention_mask'], ytest_tensor, identities_col_test)\n",
    "# Try different batch size to reduce running time\n",
    "train_dataloader = DataLoader(Xtraintorch, batch_size=128, shuffle=True)\n",
    "test_dataloader = DataLoader(Xtesttorch, batch_size=128, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to GPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "roberta2 = roberta2.to(device)\n",
    "optimizer = torch.optim.AdamW(roberta2.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty cache to avoid memory shortages \n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/196 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 187.00 MiB is free. Process 970332 has 1.66 GiB memory in use. Including non-PyTorch memory, this process has 21.81 GiB memory in use. Of the allocated memory 21.20 GiB is allocated by PyTorch, and 310.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_with_penalty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroberta2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_penalty_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 17\u001b[0m, in \u001b[0;36mtrain_with_penalty\u001b[0;34m(model, train_dataloader, optimizer, device, bias_penalty_factor)\u001b[0m\n\u001b[1;32m     14\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m identities_col \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device) \n\u001b[0;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m pred \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Compute the loss with bias regularization\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/models/roberta/modeling_roberta.py:1318\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1318\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1330\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/models/roberta/modeling_roberta.py:976\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    974\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 976\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    989\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/models/roberta/modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    622\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    628\u001b[0m         output_attentions,\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/models/roberta/modeling_roberta.py:562\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    559\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    560\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 562\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    565\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/pytorch_utils.py:256\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/models/roberta/modeling_roberta.py:574\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 574\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/models/roberta/modeling_roberta.py:473\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    472\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 473\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/nadia/lib/python3.13/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacity of 23.69 GiB of which 187.00 MiB is free. Process 970332 has 1.66 GiB memory in use. Including non-PyTorch memory, this process has 21.81 GiB memory in use. Of the allocated memory 21.20 GiB is allocated by PyTorch, and 310.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "train_with_penalty(roberta2, train_dataloader, optimizer, device, bias_penalty_factor=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurpassable out of memory error. Attempting to run the second training on a separate notebook to avoid memory issues did not fix the issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with bias\n",
    "pred2, actual2 = evaluate_model(roberta2, test_dataloader)\n",
    "mse2 = mean_squared_error(actual2, pred2)\n",
    "\n",
    "print(f'Mean Squared Error for Roberta bias mitigated model using 25000/2500 data split: {mse2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1375107,
     "sourceId": 12500,
     "sourceType": "competition"
    },
    {
     "datasetId": 6267404,
     "sourceId": 10151877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nadia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
